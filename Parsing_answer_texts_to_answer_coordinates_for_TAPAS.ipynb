{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Parsing answer texts to answer coordinates for TAPAS.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN9Evuk2Jb7NASuK8lLooh1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NielsRogge/tapas_utils/blob/master/Parsing_answer_texts_to_answer_coordinates_for_TAPAS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxdhC7N4nMlz"
      },
      "source": [
        "In this notebook, we show how you can use a parsing function (as defined in the original TAPAS repo but updated to work for the HuggingFace version of TAPAS) in order to automatically create answer coordinates based on the answer text of a given question.\n",
        "\n",
        "First, let's copy the entire function which is available in my repo [tapas_utils](https://github.com/NielsRogge/tapas_utils)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-R9_TwzVjn_y",
        "outputId": "45a8c4a0-8f6e-466e-c8f9-3694ee3d3d5e"
      },
      "source": [
        "!pip install frozendict"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting frozendict\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/55/a12ded2c426a4d2bee73f88304c9c08ebbdbadb82569ebdd6a0c007cfd08/frozendict-1.2.tar.gz\n",
            "Building wheels for collected packages: frozendict\n",
            "  Building wheel for frozendict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for frozendict: filename=frozendict-1.2-cp37-none-any.whl size=3150 sha256=345495ef3ec6411b713da7a585e6fd315e62786628aafda5d08e9432984d4148\n",
            "  Stored in directory: /root/.cache/pip/wheels/6c/6c/e9/534386165bd12cf1885582c75eb6d0ffcb321b65c23fe0f834\n",
            "Successfully built frozendict\n",
            "Installing collected packages: frozendict\n",
            "Successfully installed frozendict-1.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vj9f0yYDjaJw"
      },
      "source": [
        "# coding=utf-8\n",
        "# Copyright 2019 The Google AI Language Team Authors.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# Lint as: python3\n",
        "\"\"\"This module implements a simple parser that can be used for TAPAS.\n",
        "\n",
        "Given a table, a question and one or more answer_texts, it will parse the texts\n",
        "to populate other fields (e.g. answer_coordinates, float_value) that are required\n",
        "by TAPAS.\n",
        "\n",
        "Please note that exceptions in this module are concise and not parameterized,\n",
        "since they are used as counter names in a BEAM pipeline.\n",
        "\"\"\"\n",
        "\n",
        "import enum\n",
        "from typing import Callable, List, Text, Optional\n",
        "\n",
        "import six\n",
        "import struct\n",
        "import unicodedata\n",
        "import re\n",
        "\n",
        "import frozendict\n",
        "import numpy as np\n",
        "import scipy.optimize\n",
        "\n",
        "\n",
        "class SupervisionMode(enum.Enum):\n",
        "  # Don't filter out any supervised information.\n",
        "  NONE = 0\n",
        "  # Remove all the supervised signals and recompute them by parsing answer\n",
        "  # texts.\n",
        "  REMOVE_ALL = 2\n",
        "  # Same as above but discard ambiguous examples\n",
        "  # (where an answer matches multiple cells).\n",
        "  REMOVE_ALL_STRICT = 3\n",
        "\n",
        "\n",
        "def _find_matching_coordinates(table, answer_text,\n",
        "                               normalize):\n",
        "  normalized_text = normalize(answer_text)\n",
        "  for row_index, row in table.iterrows():\n",
        "    for column_index, cell in enumerate(row):\n",
        "      if normalized_text == normalize(str(cell)):\n",
        "        yield (row_index, column_index)\n",
        "\n",
        "\n",
        "def _compute_cost_matrix_inner(\n",
        "    table,\n",
        "    answer_texts,\n",
        "    normalize,\n",
        "    discard_ambiguous_examples,\n",
        "):\n",
        "  \"\"\"Returns a cost matrix M where the value M[i,j] contains a matching cost from answer i to cell j.\n",
        "\n",
        "  The matrix is a binary matrix and -1 is used to indicate a possible match from\n",
        "  a given answer_texts to a specific cell table. The cost matrix can then be\n",
        "  usedto compute the optimal assignments that minimizes the cost using the\n",
        "  hungarian algorithm (see scipy.optimize.linear_sum_assignment).\n",
        "\n",
        "  Args:\n",
        "    table: a Pandas dataframe.\n",
        "    answer_texts: a list of strings.\n",
        "    normalize: a function that normalizes a string.\n",
        "    discard_ambiguous_examples: If true discard if answer has multiple matches.\n",
        "\n",
        "  Raises:\n",
        "    ValueError if:\n",
        "      - we cannot correctly construct the cost matrix or the text-cell\n",
        "      assignment is ambiguous.\n",
        "      - we cannot find a matching cell for a given answer_text.\n",
        "\n",
        "  Returns:\n",
        "    A numpy matrix with shape (num_answer_texts, num_rows * num_columns).\n",
        "  \"\"\"\n",
        "  max_candidates = 0\n",
        "  n_rows, n_columns = table.shape[0], table.shape[1]\n",
        "  num_cells = n_rows * n_columns\n",
        "  num_candidates = np.zeros((n_rows, n_columns))\n",
        "  cost_matrix = np.zeros((len(answer_texts), num_cells))\n",
        "\n",
        "  for index, answer_text in enumerate(answer_texts):\n",
        "    found = 0\n",
        "    for row, column in _find_matching_coordinates(table, answer_text,\n",
        "                                                  normalize):\n",
        "      found += 1\n",
        "      cost_matrix[index, (row * len(table.columns)) + column] = -1\n",
        "      num_candidates[row, column] += 1\n",
        "      max_candidates = max(max_candidates, num_candidates[row, column])\n",
        "    if found == 0:\n",
        "      return None\n",
        "    if discard_ambiguous_examples and found > 1:\n",
        "      raise ValueError(\"Found multiple cells for answers\")\n",
        "\n",
        "  # TODO(piccinno): Shall we allow ambiguous assignments?\n",
        "  if max_candidates > 1:\n",
        "    raise ValueError(\"Assignment is ambiguous\")\n",
        "\n",
        "  return cost_matrix\n",
        "\n",
        "\n",
        "def _compute_cost_matrix(\n",
        "    table,\n",
        "    answer_texts,\n",
        "    discard_ambiguous_examples,\n",
        "):\n",
        "  \"\"\"Computes cost matrix.\"\"\"\n",
        "  for index, normalize_fn in enumerate(STRING_NORMALIZATIONS):\n",
        "    try:\n",
        "      result = _compute_cost_matrix_inner(\n",
        "          table,\n",
        "          answer_texts,\n",
        "          normalize_fn,\n",
        "          discard_ambiguous_examples,\n",
        "      )\n",
        "      if result is None:\n",
        "        continue\n",
        "      return result\n",
        "    except ValueError:\n",
        "      if index == len(STRING_NORMALIZATIONS) - 1:\n",
        "        raise\n",
        "  return None\n",
        "\n",
        "\n",
        "def _parse_answer_coordinates(table,\n",
        "                              answer_texts,\n",
        "                              discard_ambiguous_examples):\n",
        "  \"\"\"Populates answer_coordinates using answer_texts.\n",
        "\n",
        "  Args:\n",
        "    table: a Table message, needed to compute the answer coordinates.\n",
        "    answer_texts: a list of strings\n",
        "    discard_ambiguous_examples: If true discard if answer has multiple matches.\n",
        "\n",
        "  Raises:\n",
        "    ValueError if the conversion fails.\n",
        "  \"\"\"\n",
        "  \n",
        "  cost_matrix = _compute_cost_matrix(\n",
        "      table,\n",
        "      answer_texts,\n",
        "      discard_ambiguous_examples,\n",
        "  )\n",
        "  if cost_matrix is None:\n",
        "    return\n",
        "  row_indices, column_indices = scipy.optimize.linear_sum_assignment(\n",
        "      cost_matrix)\n",
        " \n",
        "  # create answer coordinates as list of tuples\n",
        "  answer_coordinates = []\n",
        "  for row_index in row_indices:\n",
        "    flatten_position = column_indices[row_index]\n",
        "    row_coordinate = flatten_position // len(table.columns)\n",
        "    column_coordinate = flatten_position % len(table.columns)\n",
        "    answer_coordinates.append((row_coordinate, column_coordinate))\n",
        "\n",
        "  return answer_coordinates\n",
        "\n",
        "\n",
        "### START OF UTILITIES FROM TEXT_UTILS.PY ###\n",
        "\n",
        "def wtq_normalize(x):\n",
        "  \"\"\"Returns the normalized version of x.\n",
        "  This normalization function is taken from WikiTableQuestions github, hence the\n",
        "  wtq prefix. For more information, see\n",
        "  https://github.com/ppasupat/WikiTableQuestions/blob/master/evaluator.py\n",
        "  Args:\n",
        "    x: the object (integer type or string) to normalize.\n",
        "  Returns:\n",
        "    A normalized string.\n",
        "  \"\"\"\n",
        "  x = x if isinstance(x, six.text_type) else six.text_type(x)\n",
        "  # Remove diacritics.\n",
        "  x = \"\".join(\n",
        "      c for c in unicodedata.normalize(\"NFKD\", x)\n",
        "      if unicodedata.category(c) != \"Mn\")\n",
        "  # Normalize quotes and dashes.\n",
        "  x = re.sub(u\"[‘’´`]\", \"'\", x)\n",
        "  x = re.sub(u\"[“”]\", '\"', x)\n",
        "  x = re.sub(u\"[‐‑‒–—−]\", \"-\", x)\n",
        "  x = re.sub(u\"[‐]\", \"\", x)\n",
        "  while True:\n",
        "    old_x = x\n",
        "    # Remove citations.\n",
        "    x = re.sub(u\"((?<!^)\\\\[[^\\\\]]*\\\\]|\\\\[\\\\d+\\\\]|[•♦†‡*#+])*$\", \"\",\n",
        "               x.strip())\n",
        "    # Remove details in parenthesis.\n",
        "    x = re.sub(u\"(?<!^)( \\\\([^)]*\\\\))*$\", \"\", x.strip())\n",
        "    # Remove outermost quotation mark.\n",
        "    x = re.sub(u'^\"([^\"]*)\"$', r\"\\1\", x.strip())\n",
        "    if x == old_x:\n",
        "      break\n",
        "  # Remove final '.'.\n",
        "  if x and x[-1] == \".\":\n",
        "    x = x[:-1]\n",
        "  # Collapse whitespaces and convert to lower case.\n",
        "  x = re.sub(r\"\\s+\", \" \", x, flags=re.U).lower().strip()\n",
        "  x = re.sub(\"<[^<]+?>\", \"\", x)\n",
        "  x = x.replace(\"\\n\", \" \")\n",
        "  return x\n",
        "\n",
        "\n",
        "_TOKENIZER = re.compile(r\"\\w+|[^\\w\\s]+\", re.UNICODE)\n",
        "\n",
        "\n",
        "def tokenize_string(x):\n",
        "  return list(_TOKENIZER.findall(x.lower()))\n",
        "\n",
        "\n",
        "# List of string normalization functions to be applied in order. We go from\n",
        "# simplest to more complex normalization procedures.\n",
        "STRING_NORMALIZATIONS = (\n",
        "    lambda x: x,\n",
        "    lambda x: x.lower(),\n",
        "    tokenize_string,\n",
        "    wtq_normalize,\n",
        ")\n",
        "\n",
        "\n",
        "def to_float32(v):\n",
        "  \"\"\"If v is a float reduce precision to that of a 32 bit float.\"\"\"\n",
        "  if not isinstance(v, float):\n",
        "    return v\n",
        "  return struct.unpack(\"!f\", struct.pack(\"!f\", v))[0]\n",
        "\n",
        "\n",
        "def convert_to_float(value):\n",
        "  \"\"\"Converts value to a float using a series of increasingly complex heuristics.\n",
        "  Args:\n",
        "    value: object that needs to be converted. Allowed types include\n",
        "      float/int/strings.\n",
        "  Returns:\n",
        "    A float interpretation of value.\n",
        "  Raises:\n",
        "    ValueError if the float conversion of value fails.\n",
        "  \"\"\"\n",
        "  if isinstance(value, float):\n",
        "    return value\n",
        "  if isinstance(value, int):\n",
        "    return float(value)\n",
        "  if not isinstance(value, six.string_types):\n",
        "    raise ValueError(\"Argument value is not a string. Can't parse it as float\")\n",
        "  sanitized = value\n",
        "\n",
        "  try:\n",
        "    # Example: 1,000.7\n",
        "    if \".\" in sanitized and \",\" in sanitized:\n",
        "      return float(sanitized.replace(\",\", \"\"))\n",
        "    # 1,000\n",
        "    if \",\" in sanitized and _split_thousands(\",\", sanitized):\n",
        "      return float(sanitized.replace(\",\", \"\"))\n",
        "    # 5,5556\n",
        "    if \",\" in sanitized and sanitized.count(\",\") == 1 and not _split_thousands(\n",
        "        \",\", sanitized):\n",
        "      return float(sanitized.replace(\",\", \".\"))\n",
        "    # 0.0.0.1\n",
        "    if sanitized.count(\".\") > 1:\n",
        "      return float(sanitized.replace(\".\", \"\"))\n",
        "    # 0,0,0,1\n",
        "    if sanitized.count(\",\") > 1:\n",
        "      return float(sanitized.replace(\",\", \"\"))\n",
        "    return float(sanitized)\n",
        "  except ValueError:\n",
        "    # Avoid adding the sanitized value in the error message.\n",
        "    raise ValueError(\"Unable to convert value to float\")\n",
        "\n",
        "### END OF UTILITIES FROM TEXT_UTILS.PY ###\n",
        "\n",
        "def _parse_answer_float(answer_texts, float_value):\n",
        "  if len(answer_texts) > 1:\n",
        "    raise ValueError(\"Cannot convert to multiple answers to single float\")\n",
        "  float_value = convert_to_float(answer_texts[0])\n",
        "  float_value = float_value\n",
        "\n",
        "  return answer_texts, float_value\n",
        "\n",
        "\n",
        "def _has_single_float_answer_equal_to(question, answer_texts, target):\n",
        "  \"\"\"Returns true if the question has a single answer whose value equals to target.\"\"\"\n",
        "  if len(answer_texts) != 1:\n",
        "    return False\n",
        "  try:\n",
        "    float_value = convert_to_float(answer_texts[0])\n",
        "    # In general answer_float is derived by applying the same conver_to_float\n",
        "    # function at interaction creation time, hence here we use exact match to\n",
        "    # avoid any false positive.\n",
        "    return to_float32(float_value) == to_float32(target)\n",
        "  except ValueError:\n",
        "    return False\n",
        "\n",
        "\n",
        "def _parse_question(\n",
        "    table,\n",
        "    original_question,\n",
        "    answer_texts,\n",
        "    answer_coordinates,\n",
        "    float_value,\n",
        "    aggregation_function,\n",
        "    clear_fields,\n",
        "    discard_ambiguous_examples,\n",
        "):\n",
        "  \"\"\"Parses question's answer_texts fields to possibly populate additional fields.\n",
        "\n",
        "  Args:\n",
        "    table: a Pandas dataframe, needed to compute the answer coordinates.\n",
        "    original_question: a string.\n",
        "    answer_texts: a list of strings, serving as the answer to the question.\n",
        "    anser_coordinates:\n",
        "    float_value: a float, serves as float value signal. \n",
        "    aggregation_function: \n",
        "    clear_fields: A list of strings indicating which fields need to be cleared\n",
        "      and possibly repopulated.\n",
        "    discard_ambiguous_examples: If true, discard ambiguous examples.\n",
        "\n",
        "  Returns:\n",
        "    A Question message with answer_coordinates or float_value field populated.\n",
        "\n",
        "  Raises:\n",
        "    ValueError if we cannot parse correctly the question message.\n",
        "  \"\"\"\n",
        "  question = original_question\n",
        "\n",
        "  # If we have a float value signal we just copy its string representation to\n",
        "  # the answer text (if multiple answers texts are present OR the answer text\n",
        "  # cannot be parsed to float OR the float value is different), after clearing\n",
        "  # this field.\n",
        "  if \"float_value\" in clear_fields and float_value is not None:\n",
        "    if not _has_single_float_answer_equal_to(question, answer_texts, float_value):\n",
        "      del answer_texts[:]\n",
        "      float_value = float(float_value)\n",
        "      if float_value.is_integer():\n",
        "        number_str = str(int(float_value))\n",
        "      else:\n",
        "        number_str = str(float_value)\n",
        "      answer_texts = []\n",
        "      answer_texts.append(number_str)\n",
        "\n",
        "  if not answer_texts:\n",
        "    raise ValueError(\"No answer_texts provided\")\n",
        "\n",
        "  for field_name in clear_fields:\n",
        "    if field_name == \"answer_coordinates\":\n",
        "        answer_coordinates = None\n",
        "    if field_name == \"float_value\":\n",
        "        float_value = None\n",
        "    if field_name == \"aggregation_function\":\n",
        "        aggregation_function = None\n",
        "\n",
        "  error_message = \"\"\n",
        "  if not answer_coordinates:\n",
        "    try:\n",
        "      answer_coordinates = _parse_answer_coordinates(\n",
        "          table,\n",
        "          answer_texts,\n",
        "          discard_ambiguous_examples,\n",
        "      )\n",
        "    except ValueError as exc:\n",
        "      error_message += \"[answer_coordinates: {}]\".format(str(exc))\n",
        "      if discard_ambiguous_examples:\n",
        "        raise ValueError(f\"Cannot parse answer: {error_message}\")\n",
        "\n",
        "  if not float_value:\n",
        "    try:\n",
        "      answer_texts, float_value = _parse_answer_float(answer_texts, float_value)\n",
        "    except ValueError as exc:\n",
        "      error_message += \"[float_value: {}]\".format(str(exc))\n",
        "\n",
        "  # Raises an exception if we cannot set any of the two fields.\n",
        "  if not answer_coordinates and not float_value:\n",
        "    raise ValueError(\"Cannot parse answer: {}\".format(error_message))\n",
        "\n",
        "  return question, answer_texts, answer_coordinates, float_value, aggregation_function\n",
        "\n",
        "\n",
        "# TODO(piccinno): Use some sort of introspection here to get the field names of\n",
        "# the proto.\n",
        "_CLEAR_FIELDS = frozendict.frozendict({\n",
        "    SupervisionMode.REMOVE_ALL: [\n",
        "        \"answer_coordinates\", \"float_value\", \"aggregation_function\"\n",
        "    ],\n",
        "    SupervisionMode.REMOVE_ALL_STRICT: [\n",
        "        \"answer_coordinates\", \"float_value\", \"aggregation_function\"\n",
        "    ]\n",
        "})\n",
        "\n",
        "\n",
        "def parse_question(table, question, answer_texts, answer_coordinates=None, float_value=None, aggregation_function=None,\n",
        "                    mode=SupervisionMode.REMOVE_ALL):\n",
        "    \"\"\"Parses answer_text field of a question to populate additional fields required by TAPAS.\n",
        "\n",
        "    Args:\n",
        "        table: a Pandas dataframe, needed to compute the answer coordinates. Note that one should apply .astype(str)\n",
        "        before supplying the table to this function. \n",
        "        question: a string.\n",
        "        answer_texts: a list of strings, containing one or more answer texts that serve as answer to the question.\n",
        "        answer_coordinates: optional answer coordinates supervision signal, if you already have those. \n",
        "        float_value: optional float supervision signal, if you already have this. \n",
        "        aggregation_function: optional aggregation function supervised signal, if you already have this. \n",
        "        mode: see SupervisionMode enum for more information.\n",
        "\n",
        "    Returns:\n",
        "        A list with the question, populated answer_coordinates or float_value.\n",
        "\n",
        "    Raises:\n",
        "        ValueError if we cannot parse correctly the question string.\n",
        "    \"\"\"\n",
        "    if mode == SupervisionMode.NONE:\n",
        "        return question, answer_texts\n",
        "\n",
        "    clear_fields = _CLEAR_FIELDS.get(mode, None)\n",
        "    if clear_fields is None:\n",
        "        raise ValueError(f\"Mode {mode.name} is not supported\")\n",
        "\n",
        "    return _parse_question(\n",
        "        table,\n",
        "        question,\n",
        "        answer_texts,\n",
        "        answer_coordinates,\n",
        "        float_value,\n",
        "        aggregation_function,\n",
        "        clear_fields,\n",
        "        discard_ambiguous_examples=mode == SupervisionMode.REMOVE_ALL_STRICT,\n",
        "    )"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ku3n6v21nfZ-"
      },
      "source": [
        "Let's define a table with some data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "T6j5fpuajiGx",
        "outputId": "89b20e30-0464-4876-c51d-2de747e47833"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = {'Actors': [\"Brad Pitt\", \"Leonardo Di Caprio\", \"George Clooney\"],\n",
        "        'Age': [\"56\", \"45\", \"59\"],\n",
        "        'Number of movies': [\"87\", \"53\", \"69\"]\n",
        "}\n",
        "table = pd.DataFrame.from_dict(data)\n",
        "\n",
        "table.head()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Actors</th>\n",
              "      <th>Age</th>\n",
              "      <th>Number of movies</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Brad Pitt</td>\n",
              "      <td>56</td>\n",
              "      <td>87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Leonardo Di Caprio</td>\n",
              "      <td>45</td>\n",
              "      <td>53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>George Clooney</td>\n",
              "      <td>59</td>\n",
              "      <td>69</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Actors Age Number of movies\n",
              "0           Brad Pitt  56               87\n",
              "1  Leonardo Di Caprio  45               53\n",
              "2      George Clooney  59               69"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZ6yGscrm4Ob"
      },
      "source": [
        "Now, let's test the `parse_question` function which is defined above. This function needs to find the answer coordinates given the table, question and answer texts.\n",
        "\n",
        "Note that you should apply `table = table.astype(str)` on your Pandas dataframe if the table does not already have text-only values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvbntjCJmO2i",
        "outputId": "7e8d27df-5923-4834-b39e-57a80c38d4fb"
      },
      "source": [
        "question = \"How old is Brad Pitt?\"\n",
        "\n",
        "answer_texts = [\"56\"]\n",
        "\n",
        "question, answer_texts, answer_coordinates, float_value, aggregation_function = parse_question(table=table, question=question, answer_texts=answer_texts)\n",
        "print(question)\n",
        "print(answer_texts)\n",
        "print(\"Found coordinates:\", answer_coordinates)\n",
        "print(\"Found float value:\", float_value)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "How old is Brad Pitt?\n",
            "['56']\n",
            "Found coordinates: [(0, 1)]\n",
            "Found float value: 56.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ou6CZS1NmSIh",
        "outputId": "eb34f708-c2a3-4d4d-da55-b1fa5e6c8421"
      },
      "source": [
        "question = \"How many movies has Leonardi Di Caprio played in?\"\n",
        "\n",
        "answer_texts = [\"53\"]\n",
        "\n",
        "question, answer_texts, answer_coordinates, float_value, aggregation_function = parse_question(table=table, question=question, answer_texts=answer_texts)\n",
        "print(question)\n",
        "print(answer_texts)\n",
        "print(\"Found coordinates:\", answer_coordinates)\n",
        "print(\"Found float value:\", float_value)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "How many movies has Leonardi Di Caprio played in?\n",
            "['53']\n",
            "Found coordinates: [(1, 2)]\n",
            "Found float value: 53.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cNPlQzDl1iu",
        "outputId": "2c20bc12-a95b-4cc1-9d12-2cd38488401b"
      },
      "source": [
        "question = \"What's the total number of movies?\"\n",
        "\n",
        "answer_texts = [\"87\", \"53\", \"69\"]\n",
        "float_value = 229\n",
        "\n",
        "question, answer_texts, answer_coordinates, float_value, aggregation_function = parse_question(table=table, question=question, answer_texts=answer_texts)\n",
        "print(question)\n",
        "print(answer_texts)\n",
        "print(\"Found coordinates:\", answer_coordinates)\n",
        "print(\"Found float value:\", float_value)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "What's the total number of movies?\n",
            "['87', '53', '69']\n",
            "Found coordinates: [(0, 2), (1, 2), (2, 2)]\n",
            "Found float value: None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5s485e6koF07"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}